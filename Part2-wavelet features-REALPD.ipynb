{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, FeaturesData, Pool\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================================\n",
    "#making time stamp uniform by Interpolation\n",
    "\n",
    "def preprocess(data):\n",
    "    freq=50\n",
    "    ls=['x','y','z']\n",
    "    t1=np.arange(data.t[0],data.t[(data.shape[0])-1],0.02)\n",
    "    df=pd.DataFrame({'Timestamp':t1})\n",
    "    for i in ls:\n",
    "        fcubic = interpolate.interp1d(data.t, data[i], kind='cubic')\n",
    "        df[i]=fcubic(t1)\n",
    "    df.columns=['Timestamp','acc_X','acc_Y','acc_Z']\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess2(data):\n",
    "    ls=['x','y','z']\n",
    "    freq=round((1/((data.t.max()/data.t.shape[0]).round(3))),0)\n",
    "    t1=np.arange(data.t[0],data.t[(data.shape[0])-1],(data.t.max()/data.t.shape[0]).round(3))\n",
    "    df=pd.DataFrame({'Timestamp':t1})\n",
    "    for i in ls:\n",
    "        fcubic = interpolate.interp1d(data.t, data[i], kind='cubic')\n",
    "        df[i]=fcubic(t1)\n",
    "    df.columns=['Timestamp','acc_X','acc_Y','acc_Z']\n",
    "    return df,freq\n",
    "\n",
    "\n",
    "def preprocess_real_smartwatch(data):\n",
    "    \n",
    "    a=data.groupby('device_id').agg({'x':'var','y':'count'}).reset_index()\n",
    "    deviceid=a.loc[a.x.idxmax(),'device_id']\n",
    "    if int(a.loc[a.device_id==deviceid,'y'])<=data.shape[0]*0.2:\n",
    "        deviceid=a.loc[a.x.idxmin(),'device_id']\n",
    "    \n",
    "    data=data[data.device_id==deviceid].reset_index()\n",
    "    data.rename(columns={'t':'Timestamp','x':'X','y':'Y','z':'Z'},inplace=True)\n",
    "   \n",
    "    ls=['X','Y','Z']\n",
    "    freq=50\n",
    "    #freq=round((1/((data.Timestamp.max()/data.Timestamp.shape[0]).round(3))),0)\n",
    "    t1=np.arange(data.Timestamp[0],data.Timestamp[(data.shape[0])-1],0.02)\n",
    "    #t1=np.arange(data.Timestamp[0],data.Timestamp[(data.shape[0])-1],(data.Timestamp.max()/data.Timestamp.shape[0]).round(3))\n",
    "    df=pd.DataFrame({'Timestamp':t1})\n",
    "        \n",
    "    for i in ls:\n",
    "        fcubic = interpolate.interp1d(data.Timestamp, data[i])\n",
    "        df[i]=fcubic(t1)\n",
    "    df.rename(columns={'X':'acc_X','Y':'acc_Y','Z':'acc_Z'},inplace=True)\n",
    "    return df[['Timestamp','acc_X','acc_Y','acc_Z']],deviceid,freq\n",
    "\n",
    "#==========================================================================================\n",
    "#median filter\n",
    "from scipy.signal import medfilt # import the median filter function\n",
    "def median(signal):# input: numpy array 1D (one column)  \n",
    "    #applying the median filter\n",
    "    return  medfilt(np.array(signal), kernel_size=3) # applying the median filter order3(kernel_size=3)\n",
    "\n",
    "\n",
    "#==========================================================================================\n",
    "#components_selection_one_signal\n",
    "import math # import math library\n",
    "\n",
    "\n",
    "def components_selection_one_signal(t_signal,sampling_freq):\n",
    "    nyq=sampling_freq/float(2) # nyq is the nyquist frequency equal to the half of the sampling frequency[50/2= 25 Hz]\n",
    "\n",
    "    freq1 = 0.3\n",
    "    freq2 = 20\n",
    "\n",
    "    t_signal=np.array(t_signal)\n",
    "    t_signal_length=len(t_signal) # number of points in a t_signal\n",
    "    \n",
    "    # the t_signal in frequency domain after applying fft\n",
    "    f_signal=np.fft.fft(t_signal) # 1D numpy array contains complex values (in C)\n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    freqs=np.array(np.fft.fftfreq(t_signal_length, d=1/float(sampling_freq))) # frequency values between [-25hz:+25hz]\n",
    "        \n",
    "    df=pd.DataFrame({'freq':abs(freqs),'amplitute':f_signal})\n",
    "    df['f_DC_signal']=np.where(df.freq>freq1,0,df.amplitute)\n",
    "    df['f_noise_signal']=np.where(df.freq<=freq2,0,df.amplitute)\n",
    "    df['f_body_signal']=np.where(df.freq<=freq1,0,np.where(df.freq>freq2,0,df.amplitute))\n",
    "\n",
    "    \n",
    "    # Inverse the transformation of signals in freq domain #\n",
    "    # applying the inverse fft(ifft) to signals in freq domain and put them in float format\n",
    "    t_DC_component= np.fft.ifft(np.array(df['f_DC_signal'])).real\n",
    "    t_body_component= np.fft.ifft(np.array(df['f_body_signal'])).real\n",
    "    t_noise=np.fft.ifft(np.array(df['f_noise_signal'])).real\n",
    "    \n",
    "    total_component=t_signal-t_noise # extracting the total component(filtered from noise) \n",
    "                                     #  by substracting noise from t_signal (the original signal).\n",
    "    \n",
    "    # return outputs mentioned earlier\n",
    "    return (total_component,t_DC_component,t_body_component,t_noise) \n",
    "\n",
    "\n",
    "#=================================================================================================================\n",
    "#Define verify gravity function\n",
    "def mag_3_signals(df): # Euclidian magnitude\n",
    "    return np.array(np.sqrt(np.square(df).sum(axis=1)))\n",
    "\n",
    "def verify_gravity(data):\n",
    "    \n",
    "    acc_x=np.array(data['acc_X']) # copy acc_X column from dataframe in raw_dic having the key mentioned above\n",
    "    acc_y=np.array(data['acc_Y'])# copy acc_Y column  from dataframe in raw_dic having the key mentioned above\n",
    "    acc_z=np.array(data['acc_Z'])# copy acc_Z column  from dataframe in raw_dic having the key mentioned above\n",
    "\n",
    "    # apply the filtering method to acc_[X,Y,Z] and store gravity components\n",
    "    grav_acc_X=components_selection_one_signal(acc_x)[1] \n",
    "    grav_acc_Y=components_selection_one_signal(acc_y)[1]\n",
    "    grav_acc_Z=components_selection_one_signal(acc_z)[1]\n",
    "    \n",
    "    # calculating gravity magnitude signal\n",
    "    grav_acc_mag=mag_3_signals(grav_acc_X, grav_acc_Y,grav_acc_Z)\n",
    "    print('mean value = ',round((sum(grav_acc_mag) / len(grav_acc_mag)),3),' g')\n",
    "    \n",
    "#=================================================================================================================    \n",
    "#Define jerking and magnitude functions\n",
    "def jerk_one_signal(signal,sampling_freq):\n",
    "    signal=pd.DataFrame(signal)\n",
    "    jerk=(signal.shift(-1)-signal)*sampling_freq\n",
    "    return np.array(jerk.dropna()).transpose()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Id label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "cis_pd_testing_id=pd.read_csv('test_data_Id/cis-pd.CIS-PD_Test_Data_IDs.csv')\n",
    "real_pd_testing_id=pd.read_csv('test_data_Id/real-pd.REAL-PD_Test_Data_IDs.csv')\n",
    "\n",
    "#Training Data\n",
    "cis_pd_training_id=pd.read_csv('data_labels/CIS-PD_Training_Data_IDs_Labels.csv')\n",
    "real_pd_training_id=pd.read_csv('data_labels/REAL-PD_Training_Data_IDs_Labels.csv')\n",
    "\n",
    "#Ancillary Data\n",
    "cis_pd_ancillary_id=pd.read_csv('data_labels/CIS-PD_Ancillary_Data_IDs_Labels.csv')\n",
    "real_pd_ancillary_id=pd.read_csv('data_labels/REAL-PD_Ancillary_Data_IDs_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_signal(data,sampling_freq):\n",
    "    time_sig_df=pd.DataFrame()\n",
    "    for column in ['acc_X','acc_Y','acc_Z']:\n",
    "        t_signal=np.array(data[column])\n",
    "        #med_filtred=median(t_signal)\n",
    "        med_filtred=(t_signal)\n",
    "        _,grav_acc,body_acc,_=components_selection_one_signal(med_filtred,sampling_freq)\n",
    "        body_acc_jerk=jerk_one_signal(body_acc,sampling_freq)\n",
    "        time_sig_df['t_body_'+column]=body_acc[:-1]\n",
    "        time_sig_df['t_grav_'+column]= grav_acc[:-1]\n",
    "        time_sig_df['t_body_acc_jerk_'+column[-1]]=body_acc_jerk\n",
    "\n",
    "    # all 15 axial signals generated above are reordered to facilitate magnitudes signals generation\n",
    "    new_columns_ordered=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                              't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                              't_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z']\n",
    "\n",
    "\n",
    "    # create new dataframe to order columns\n",
    "    time_sig_df=time_sig_df[new_columns_ordered]\n",
    "\n",
    "    # Magnitude Features\n",
    "    for i in range(0,9,3):\n",
    "        mag_col_name=new_columns_ordered[i][:-1]+'mag'# Create the magnitude column name related to each 3-axial signals\n",
    "        time_sig_df[mag_col_name]=mag_3_signals(time_sig_df[new_columns_ordered[i:i+3]]) # store the signal_mag with its appropriate column name\n",
    "\n",
    "    return(time_sig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=glob.glob(\"training_data/smartphone_accelerometer/*.csv\")\n",
    "data=preprocess(pd.read_csv(a[14]))\n",
    "time_sig_df=time_domain_signal(data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet(dfl,ls):\n",
    "    num=16\n",
    "    scales= np.arange(1,num+1)\n",
    "    pca = PCA(n_components=1)\n",
    "    df2,sampling_freq=preprocess2(pd.read_csv(dfl))\n",
    "    time_sig_df=time_domain_signal(df2,sampling_freq)\n",
    "    wavelet_coeff=[]\n",
    "    columns=time_sig_df.columns\n",
    "    for i in columns:\n",
    "        coeff, freq = pywt.cwt(time_sig_df[i],scales,ls)\n",
    "        wavelet_coeff.append(list(pca.fit_transform(coeff).flatten()))\n",
    "    return list(np.reshape(wavelet_coeff, (1,len(columns)*num))[0])\n",
    "\n",
    "def wavelet_real_smartwatch(dfl,ls):\n",
    "    num=16\n",
    "    scales= np.arange(1,num+1)\n",
    "    pca = PCA(n_components=1)\n",
    "    df2,devide_id,sampling_freq=preprocess_real_smartwatch(pd.read_csv(dfl))\n",
    "    time_sig_df=time_domain_signal(df2,sampling_freq)\n",
    "    wavelet_coeff=[]\n",
    "    columns=time_sig_df.columns\n",
    "    #columns=['t_body_acc_Z','t_grav_acc_Z','t_body_acc_jerk_Z','t_body_acc_mag','t_grav_acc_mag','t_body_acc_jerk_mag']\n",
    "    for i in columns:\n",
    "        coeff, freq = pywt.cwt(time_sig_df[i],scales,ls)\n",
    "        wavelet_coeff.append(list(pca.fit_transform(coeff).flatten()))\n",
    "    return [devide_id]+list(np.reshape(wavelet_coeff, (1,len(columns)*num))[0])\n",
    "\n",
    "\n",
    "def wavelet_real_smartwatch_gyro(dfl,ls):\n",
    "    num=16\n",
    "    scales= np.arange(1,num+1)\n",
    "    pca = PCA(n_components=1)\n",
    "    df2,devide_id,sampling_freq=preprocess_real_smartwatch(pd.read_csv(dfl))\n",
    "    time_sig_df=time_domain_signal(df2,sampling_freq)\n",
    "    wavelet_coeff=[]\n",
    "    #columns=time_sig_df.columns\n",
    "    columns=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z','t_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z','t_body_acc_mag','t_body_acc_jerk_mag']\n",
    "    for i in columns:\n",
    "        coeff, freq = pywt.cwt(time_sig_df[i],scales,ls)\n",
    "        wavelet_coeff.append(list(pca.fit_transform(coeff).flatten()))\n",
    "    return [devide_id]+list(np.reshape(wavelet_coeff, (1,len(columns)*num))[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smartphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "a=glob.glob(\"training_data/smartphone_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 9.026943965752919 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(time_sig_df.columns)\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('training_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ancillary_data\n",
    "a=glob.glob(\"ancillary_data/smartphone_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 7.226141568024953 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=pd.DataFrame(result)\n",
    "df_train2.columns=[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train2['measurement_id']=[item[len('ancillary_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame = df_train.append(pd.DataFrame(df_train2), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export part2 features from smartphone data of training data for realpd\n",
    "Frame.to_csv('realpd_wavelet_features_smartphone_training.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "a=glob.glob(\"testing_data/smartphone_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 9.026943965752919 Mins ---\n",
    "\n",
    "columns=list(time_sig_df.columns)\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('testing_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export part2 features from smartphone data of testing data for realpd\n",
    "df_train.to_csv('realpd_wavelet_features_smartphone_testing.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smartwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accelerometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "a=glob.glob(\"training_data/smartwatch_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 7.979812415440877 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(time_sig_df.columns)\n",
    "#columns=['t_body_acc_Z','t_grav_acc_Z','t_body_acc_jerk_Z','t_body_acc_mag','t_grav_acc_mag','t_body_acc_jerk_mag']\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('training_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ancillary\n",
    "a=glob.glob(\"ancillary_data/smartwatch_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 2.26669598420461 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=pd.DataFrame(result)\n",
    "df_train2.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train2['measurement_id']=[item[len('ancillary_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging training and ancillary\n",
    "Frame_smartwatch_accelerometer = df_train.append(pd.DataFrame(df_train2), ignore_index=True)\n",
    "Frame_smartwatch_accelerometer.columns=['device_id_acc']+list(Frame_smartwatch_accelerometer.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "a=glob.glob(\"testing_data/smartwatch_accelerometer/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 7.979812415440877 Mins ---\n",
    "\n",
    "columns=list(time_sig_df.columns)\n",
    "#columns=['t_body_acc_Z','t_grav_acc_Z','t_body_acc_jerk_Z','t_body_acc_mag','t_grav_acc_mag','t_body_acc_jerk_mag']\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('testing_data/smartphone_accelerometer/'):-4] for item in a]\n",
    "Frame_smartwatch_accelerometer_test=df_train.copy()\n",
    "Frame_smartwatch_accelerometer_test.columns=['device_id_acc']+list(Frame_smartwatch_accelerometer_test.columns)[1:]\n",
    "print(Frame_smartwatch_accelerometer_test.shape)\n",
    "Frame_smartwatch_accelerometer_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "a=glob.glob(\"training_data/smartwatch_gyroscope/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch_gyro)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 5.405052049954732 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z','t_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z','t_body_acc_mag','t_body_acc_jerk_mag']\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('training_data/smartwatch_gyroscope/'):-4] for item in a]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ancillary\n",
    "a=glob.glob(\"ancillary_data/smartwatch_gyroscope/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch_gyro)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 2.26669598420461 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=pd.DataFrame(result)\n",
    "df_train2.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train2['measurement_id']=[item[len('ancillary_data/smartwatch_gyroscope/'):-4] for item in a]\n",
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging training and ancillary\n",
    "Frame_smartwatch_gyro = df_train.append(pd.DataFrame(df_train2), ignore_index=True)\n",
    "Frame_smartwatch_gyro.columns=[i.replace('acc','gyro') for i in list(Frame_smartwatch_gyro.columns)]\n",
    "Frame_smartwatch_gyro.columns=['device_id_gyro']+list(Frame_smartwatch_gyro.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "a=glob.glob(\"testing_data/smartwatch_gyroscope/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet_real_smartwatch_gyro)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 5.405052049954732 Mins ---\n",
    "\n",
    "columns=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z','t_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z','t_body_acc_mag','t_body_acc_jerk_mag']\n",
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns=['device_id']+[\"wavelet_coeff_\" + suit + '_' + str(i) for suit,i in zip(list(np.repeat(columns,16)),list(np.arange(1,17))*len(columns))]\n",
    "df_train['measurement_id']=[item[len('testing_data/smartwatch_gyroscope/'):-4] for item in a]\n",
    "\n",
    "Frame_smartwatch_gyro_test=df_train.copy()\n",
    "Frame_smartwatch_gyro_test.columns=[i.replace('acc','gyro') for i in list(Frame_smartwatch_gyro_test.columns)]\n",
    "Frame_smartwatch_gyro_test.columns=['device_id_gyro']+list(Frame_smartwatch_gyro_test.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergining smartwatch_accelerometer & smartwatch_gyroscope\n",
    "Frame_smartwatch=pd.merge(Frame_smartwatch_accelerometer,Frame_smartwatch_gyro,on='measurement_id')\n",
    "Frame_smartwatch=Frame_smartwatch.drop('device_id_gyro',axis=1)\n",
    "\n",
    "Frame_smartwatch_test=pd.merge(Frame_smartwatch_accelerometer_test,Frame_smartwatch_gyro_test,on='measurement_id')\n",
    "Frame_smartwatch_test=Frame_smartwatch_test.drop('device_id_gyro',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export part2 features from smartwatch of training data for realpd\n",
    "Frame_smartwatch.to_csv('realpd_wavelet_features_smartwatch_training.csv',index=False)\n",
    "\n",
    "#export part2 features from smartwatch of testing data for realpd\n",
    "Frame_smartwatch_test.to_csv('realpd_wavelet_features_smartwatch_testing.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

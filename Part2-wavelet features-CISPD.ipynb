{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, FeaturesData, Pool\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================================\n",
    "#making time stamp uniform by Interpolation\n",
    "\n",
    "def preprocess(data):\n",
    "    freq=50\n",
    "    ls=['X','Y','Z']\n",
    "    t1=np.arange(data.Timestamp[0],data.Timestamp[(data.shape[0])-1],0.02)\n",
    "    df=pd.DataFrame({'Timestamp':t1})\n",
    "    for i in ls:\n",
    "        fcubic = interpolate.interp1d(data.Timestamp, data[i], kind='cubic')\n",
    "        df[i]=fcubic(t1)\n",
    "    df.columns=['Timestamp','acc_X','acc_Y','acc_Z']\n",
    "    return df\n",
    "\n",
    "#==========================================================================================\n",
    "#median filter\n",
    "from scipy.signal import medfilt # import the median filter function\n",
    "def median(signal):# input: numpy array 1D (one column)  \n",
    "    #applying the median filter\n",
    "    return  medfilt(np.array(signal), kernel_size=3) # applying the median filter order3(kernel_size=3)\n",
    "\n",
    "\n",
    "#==========================================================================================\n",
    "#components_selection_one_signal\n",
    "import math # import math library\n",
    "\n",
    "\n",
    "def components_selection_one_signal(t_signal):\n",
    "    sampling_freq=50\n",
    "    nyq=sampling_freq/float(2) # nyq is the nyquist frequency equal to the half of the sampling frequency[50/2= 25 Hz]\n",
    "\n",
    "    freq1 = 0.3\n",
    "    freq2 = 20\n",
    "\n",
    "    t_signal=np.array(t_signal)\n",
    "    t_signal_length=len(t_signal) # number of points in a t_signal\n",
    "    \n",
    "    # the t_signal in frequency domain after applying fft\n",
    "    f_signal=np.fft.fft(t_signal) # 1D numpy array contains complex values (in C)\n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    freqs=np.array(np.fft.fftfreq(t_signal_length, d=1/float(sampling_freq))) # frequency values between [-25hz:+25hz]\n",
    "        \n",
    "    df=pd.DataFrame({'freq':abs(freqs),'amplitute':f_signal})\n",
    "    df['f_DC_signal']=np.where(df.freq>freq1,0,df.amplitute)\n",
    "    df['f_noise_signal']=np.where(df.freq<=freq2,0,df.amplitute)\n",
    "    df['f_body_signal']=np.where(df.freq<=freq1,0,np.where(df.freq>freq2,0,df.amplitute))\n",
    "\n",
    "    \n",
    "    # Inverse the transformation of signals in freq domain #\n",
    "    # applying the inverse fft(ifft) to signals in freq domain and put them in float format\n",
    "    t_DC_component= np.fft.ifft(np.array(df['f_DC_signal'])).real\n",
    "    t_body_component= np.fft.ifft(np.array(df['f_body_signal'])).real\n",
    "    t_noise=np.fft.ifft(np.array(df['f_noise_signal'])).real\n",
    "    \n",
    "    total_component=t_signal-t_noise # extracting the total component(filtered from noise) \n",
    "                                     #  by substracting noise from t_signal (the original signal).\n",
    "    \n",
    "    # return outputs mentioned earlier\n",
    "    return (total_component,t_DC_component,t_body_component,t_noise) \n",
    "\n",
    "\n",
    "#=================================================================================================================\n",
    "#Define verify gravity function\n",
    "def mag_3_signals(df): # Euclidian magnitude\n",
    "    return np.array(np.sqrt(np.square(df).sum(axis=1)))\n",
    "\n",
    "def verify_gravity(data):\n",
    "    \n",
    "    acc_x=np.array(data['acc_X']) # copy acc_X column from dataframe in raw_dic having the key mentioned above\n",
    "    acc_y=np.array(data['acc_Y'])# copy acc_Y column  from dataframe in raw_dic having the key mentioned above\n",
    "    acc_z=np.array(data['acc_Z'])# copy acc_Z column  from dataframe in raw_dic having the key mentioned above\n",
    "\n",
    "    # apply the filtering method to acc_[X,Y,Z] and store gravity components\n",
    "    grav_acc_X=components_selection_one_signal(acc_x)[1] \n",
    "    grav_acc_Y=components_selection_one_signal(acc_y)[1]\n",
    "    grav_acc_Z=components_selection_one_signal(acc_z)[1]\n",
    "    \n",
    "    # calculating gravity magnitude signal\n",
    "    grav_acc_mag=mag_3_signals(grav_acc_X, grav_acc_Y,grav_acc_Z)\n",
    "    print('mean value = ',round((sum(grav_acc_mag) / len(grav_acc_mag)),3),' g')\n",
    "    \n",
    "#=================================================================================================================    \n",
    "#Define jerking and magnitude functions\n",
    "def jerk_one_signal(signal):\n",
    "    signal=pd.DataFrame(signal)\n",
    "    jerk=(signal.shift(-1)-signal)/0.02\n",
    "    return np.array(jerk.dropna()).transpose()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Id label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "cis_pd_testing_id=pd.read_csv('test_data_Id/cis-pd.CIS-PD_Test_Data_IDs.csv')\n",
    "real_pd_testing_id=pd.read_csv('test_data_Id/real-pd.REAL-PD_Test_Data_IDs.csv')\n",
    "\n",
    "#Training Data\n",
    "cis_pd_training_id=pd.read_csv('data_labels/CIS-PD_Training_Data_IDs_Labels.csv')\n",
    "real_pd_training_id=pd.read_csv('data_labels/REAL-PD_Training_Data_IDs_Labels.csv')\n",
    "\n",
    "#Ancillary Data\n",
    "cis_pd_ancillary_id=pd.read_csv('data_labels/CIS-PD_Ancillary_Data_IDs_Labels.csv')\n",
    "real_pd_ancillary_id=pd.read_csv('data_labels/REAL-PD_Ancillary_Data_IDs_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_signal(data):\n",
    "    time_sig_df=pd.DataFrame()\n",
    "    for column in ['acc_X','acc_Y','acc_Z']:\n",
    "        t_signal=np.array(data[column])\n",
    "        #med_filtred=median(t_signal)\n",
    "        med_filtred=(t_signal)\n",
    "        _,grav_acc,body_acc,_=components_selection_one_signal(med_filtred)\n",
    "        body_acc_jerk=jerk_one_signal(body_acc)\n",
    "        time_sig_df['t_body_'+column]=body_acc[:-1]\n",
    "        time_sig_df['t_grav_'+column]= grav_acc[:-1]\n",
    "        time_sig_df['t_body_acc_jerk_'+column[-1]]=body_acc_jerk\n",
    "\n",
    "    # all 15 axial signals generated above are reordered to facilitate magnitudes signals generation\n",
    "    new_columns_ordered=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                              't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                              't_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z']\n",
    "\n",
    "\n",
    "    # create new dataframe to order columns\n",
    "    time_sig_df=time_sig_df[new_columns_ordered]\n",
    "\n",
    "    # Magnitude Features\n",
    "    for i in range(0,9,3):\n",
    "        mag_col_name=new_columns_ordered[i][:-1]+'mag'# Create the magnitude column name related to each 3-axial signals\n",
    "        time_sig_df[mag_col_name]=mag_3_signals(time_sig_df[new_columns_ordered[i:i+3]]) # store the signal_mag with its appropriate column name\n",
    "\n",
    "    return(time_sig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=glob.glob(\"training_data/*.csv\")\n",
    "data=preprocess(pd.read_csv(a[14]))\n",
    "time_sig_df=time_domain_signal(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet(dfl,ls):\n",
    "    num=16\n",
    "    scales= np.arange(1,num+1)\n",
    "    pca = PCA(n_components=1)\n",
    "    df2=preprocess(pd.read_csv(dfl))\n",
    "    time_sig_df=time_domain_signal(df2)\n",
    "    wavelet_coeff=[]\n",
    "    for i in time_sig_df.columns:\n",
    "        coeff, freq = pywt.cwt(time_sig_df[i],scales,ls)\n",
    "        wavelet_coeff.append(list(pca.fit_transform(coeff).flatten()))\n",
    "    return list(np.reshape(wavelet_coeff, (1,len(time_sig_df.columns)*num))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train data\n",
    "a=glob.glob(\"training_data/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))\n",
    "#--- 18.011835567156474 Mins ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(result)\n",
    "df_train.columns='wavelet_coeff_'+np.repeat(time_sig_df.columns,16)+'_'+list(np.arange(1,17).astype('str'))*len(time_sig_df.columns)\n",
    "df_train['measurement_id']=[item[len('training_data/'):-4] for item in a]\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anciliary data\n",
    "a=glob.glob(\"ancillary_data/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "print(\"--- %s Mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=pd.DataFrame(result)\n",
    "df_train2.columns='wavelet_coeff_'+np.repeat(time_sig_df.columns,16)+'_'+list(np.arange(1,17).astype('str'))*len(time_sig_df.columns)\n",
    "df_train2['measurement_id']=[item[len('ancillary_data/'):-4] for item in a]\n",
    "print(df_train2.shape)\n",
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending train and anciliary\n",
    "Frame = df_train.append(pd.DataFrame(df_train2), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export part2 features of training data for cispd\n",
    "Frame.to_csv('cispd_wavelet_training_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "a=glob.glob(\"testing_data/*.csv\")\n",
    "start_time = time.time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "result=Parallel(n_jobs=num_cores)(delayed(wavelet)(i,'morl') for i in a)\n",
    "\n",
    "\n",
    "df_test=pd.DataFrame(result)\n",
    "df_test.columns='wavelet_coeff_'+np.repeat(time_sig_df.columns,16)+'_'+list(np.arange(1,17).astype('str'))*len(time_sig_df.columns)\n",
    "df_test['measurement_id']=[item[len('testing_data/'):-4] for item in a]\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export part2 features of testing data for cispd\n",
    "df_test.to_csv('cispd_wavelet_testing_features.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
